{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liiilhhh02/myhero/blob/main/notebooks/optuna_lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyyN-2qyK_T2"
      },
      "source": [
        "# Hyperparameter tuning with Optuna\n",
        "\n",
        "Github repo: https://github.com/araffin/tools-for-robotic-rl-icra2022\n",
        "\n",
        "Optuna: https://github.com/optuna/optuna\n",
        "\n",
        "Stable-Baselines3: https://github.com/DLR-RM/stable-baselines3\n",
        "\n",
        "Documentation: https://stable-baselines3.readthedocs.io/en/master/\n",
        "\n",
        "SB3 Contrib: https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\n",
        "\n",
        "RL Baselines3 zoo: https://github.com/DLR-RM/rl-baselines3-zoo\n",
        "\n",
        "[RL Baselines3 Zoo](https://github.com/DLR-RM/rl-baselines3-zoo) is a collection of pre-trained Reinforcement Learning agents using Stable-Baselines3.\n",
        "\n",
        "It also provides basic scripts for training, evaluating agents, tuning hyperparameters and recording videos.\n",
        "\n",
        "\n",
        "## Introduction\n",
        "\n",
        "In this notebook, you will learn the importance of tuning hyperparameters. You will first try to optimize the parameters manually and then we will see how to automate the search using Optuna.\n",
        "\n",
        "\n",
        "## Install Dependencies and Stable Baselines3 Using Pip\n",
        "\n",
        "List of full dependencies can be found in the [README](https://github.com/DLR-RM/stable-baselines3).\n",
        "\n",
        "\n",
        "```\n",
        "pip install stable-baselines3[extra]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hYdv2ygjLaFL",
        "vscode": {
          "languageId": "python"
        },
        "outputId": "1b39f6dc-5e13-42b4-8400-9867656cef50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stable-baselines3\n",
            "  Downloading stable_baselines3-2.7.1-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: gymnasium<1.3.0,>=0.29.1 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (1.2.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (2.0.2)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (2.9.0+cu126)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (3.1.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable-baselines3) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable-baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->stable-baselines3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->stable-baselines3) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3.0,>=2.3->stable-baselines3) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3.0,>=2.3->stable-baselines3) (3.0.3)\n",
            "Downloading stable_baselines3-2.7.1-py3-none-any.whl (188 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.0/188.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: stable-baselines3\n",
            "Successfully installed stable-baselines3-2.7.1\n"
          ]
        }
      ],
      "source": [
        "!pip install stable-baselines3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oexj67yWN5_k",
        "vscode": {
          "languageId": "python"
        },
        "outputId": "0d1818df-601f-4185-d1d8-864b7cde9c08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sb3-contrib\n",
            "  Downloading sb3_contrib-2.7.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: stable_baselines3<3.0,>=2.7.0 in /usr/local/lib/python3.12/dist-packages (from sb3-contrib) (2.7.1)\n",
            "Requirement already satisfied: gymnasium<1.3.0,>=0.29.1 in /usr/local/lib/python3.12/dist-packages (from stable_baselines3<3.0,>=2.7.0->sb3-contrib) (1.2.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.12/dist-packages (from stable_baselines3<3.0,>=2.7.0->sb3-contrib) (2.0.2)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.12/dist-packages (from stable_baselines3<3.0,>=2.7.0->sb3-contrib) (2.9.0+cu126)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from stable_baselines3<3.0,>=2.7.0->sb3-contrib) (3.1.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from stable_baselines3<3.0,>=2.7.0->sb3-contrib) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from stable_baselines3<3.0,>=2.7.0->sb3-contrib) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable_baselines3<3.0,>=2.7.0->sb3-contrib) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable_baselines3<3.0,>=2.7.0->sb3-contrib) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3-contrib) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3-contrib) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3-contrib) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3-contrib) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3-contrib) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3-contrib) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3-contrib) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3-contrib) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3-contrib) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3-contrib) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3-contrib) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3-contrib) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3-contrib) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3-contrib) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3-contrib) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3-contrib) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3-contrib) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3-contrib) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3-contrib) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3-contrib) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3-contrib) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3-contrib) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.7.0->sb3-contrib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.7.0->sb3-contrib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.7.0->sb3-contrib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.7.0->sb3-contrib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.7.0->sb3-contrib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.7.0->sb3-contrib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.7.0->sb3-contrib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.7.0->sb3-contrib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->stable_baselines3<3.0,>=2.7.0->sb3-contrib) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->stable_baselines3<3.0,>=2.7.0->sb3-contrib) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3<3.0,>=2.7.0->sb3-contrib) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3-contrib) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3-contrib) (3.0.3)\n",
            "Downloading sb3_contrib-2.7.1-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sb3-contrib\n",
            "Successfully installed sb3-contrib-2.7.1\n"
          ]
        }
      ],
      "source": [
        "# Optional: install SB3 contrib to have access to additional algorithms\n",
        "!pip install sb3-contrib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NNah91r9x9EL",
        "vscode": {
          "languageId": "python"
        },
        "outputId": "420f5d61-ad76-4366-87d1-20abccbae0ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.6.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.2)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.45)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n",
            "Downloading optuna-4.6.0-py3-none-any.whl (404 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, optuna\n",
            "Successfully installed colorlog-6.10.1 optuna-4.6.0\n"
          ]
        }
      ],
      "source": [
        "# Optuna will be used in the last part when doing hyperparameter tuning\n",
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtY8FhliLsGm"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BIedd7Pz9sOs",
        "vscode": {
          "languageId": "python"
        },
        "outputId": "5533c763-fed5-4ac3-f551-744bff9ce4a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ],
      "source": [
        "import gym\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ae32CtgzTG3R"
      },
      "source": [
        "The first thing you need to import is the RL model, check the documentation to know what you can use on which problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "R7tKaBFrTR0a",
        "vscode": {
          "languageId": "python"
        },
        "outputId": "cf1457bc-df21-4873-d73f-443a9cf54571",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ],
      "source": [
        "from stable_baselines3 import PPO, A2C, SAC, TD3, DQN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EcsXmYRMON9W",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Algorithms from the contrib repo\n",
        "# https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\n",
        "from sb3_contrib import QRDQN, TQC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kLwjcfvuqtGE",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.evaluation import evaluate_policy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-khNkrgcI6Z1"
      },
      "source": [
        "# Part I: The Importance Of Tuned Hyperparameters\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PytOtL9GdmrE"
      },
      "source": [
        "When compared with Supervised Learning, Deep Reinforcement Learning is far more sensitive to the choice of hyper-parameters such as learning rate, number of neurons, number of layers, optimizer ... etc.\n",
        "\n",
        "Poor choice of hyper-parameters can lead to poor/unstable convergence. This challenge is compounded by the variability in performance across random seeds (used to initialize the network weights and the environment)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hk8HSIC3qUjc"
      },
      "source": [
        "In addition to hyperparameters, selecting the appropriate algorithm is also an important choice. We will demonstrate it on the simple Pendulum task.\n",
        "\n",
        "See [gym doc](https://gym.openai.com/envs/Pendulum-v0/): \"The inverted pendulum swingup problem is a classic problem in the control literature. In this version  of the problem, the pendulum starts in a random position, and the goal is to swing it up so it stays upright.\"\n",
        "\n",
        "\n",
        "Let's try first with PPO and a small budget of 4000 steps (20 episodes):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4ToIvihGq2N0",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "env_id = \"Pendulum-v1\"\n",
        "# Env used only for evaluation\n",
        "eval_envs = make_vec_env(env_id, n_envs=10)\n",
        "# 4000 training timesteps\n",
        "budget_pendulum = 4000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWT2r6QE4yew"
      },
      "source": [
        "### PPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KCHk_-_4ndux",
        "vscode": {
          "languageId": "python"
        },
        "outputId": "633c5924-af27-4dfc-8de7-8ce3f5204842",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ],
      "source": [
        "ppo_model = PPO(\"MlpPolicy\", env_id, seed=0, verbose=0).learn(budget_pendulum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TP9C9AqLndxz",
        "outputId": "fddf9298-1af0-403f-9d64-9b9fdf55d7a1",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PPO Mean episode reward: -1135.93 +/- 214.94\n"
          ]
        }
      ],
      "source": [
        "mean_reward, std_reward = evaluate_policy(ppo_model, eval_envs, n_eval_episodes=100, deterministic=True)\n",
        "\n",
        "print(f\"PPO Mean episode reward: {mean_reward:.2f} +/- {std_reward:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHmJaJLl5ds4"
      },
      "source": [
        "### A2C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLL_pws25jh0",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Define and train a A2C model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ic83jZwB5nVk",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Evaluate the train A2C model\n",
        "mean_reward, std_reward = ...\n",
        "\n",
        "print(f\"A2C Mean episode reward: {mean_reward:.2f} +/- {std_reward:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_z1zFx2rVpG"
      },
      "source": [
        "Both are far from solving the env (mean reward around -200).\n",
        "Now, let's try with an off-policy algorithm:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wYaVZJU5VL5"
      },
      "source": [
        "### Training longer PPO ?\n",
        "\n",
        "Maybe training longer would help?\n",
        "\n",
        "You can try with 10x the budget, but in the case of A2C/PPO, training longer won't help much, finding better hyperparameters is needed instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "hHsHpnQY6TWA",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# train longer\n",
        "new_budget = 10 * budget_pendulum\n",
        "\n",
        "ppo_model = PPO(\"MlpPolicy\", env_id, seed=0, verbose=0).learn(new_budget)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7OD9y1o36Xta",
        "vscode": {
          "languageId": "python"
        },
        "outputId": "e36feb85-f3d1-4683-d251-bada8f328065",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PPO Mean episode reward: -1140.58 +/- 217.78\n"
          ]
        }
      ],
      "source": [
        "mean_reward, std_reward = evaluate_policy(ppo_model, eval_envs, n_eval_episodes=100, deterministic=True)\n",
        "\n",
        "print(f\"PPO Mean episode reward: {mean_reward:.2f} +/- {std_reward:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEvQ9SJ15Xmh"
      },
      "source": [
        "### PPO - Tuned Hyperparameters\n",
        "\n",
        "Using Optuna, we can in fact tune the hyperparameters and find a working solution (from the [RL Zoo](https://github.com/DLR-RM/rl-baselines3-zoo/blob/master/hyperparams/ppo.yml)):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "S-D_vvsb6jOZ",
        "vscode": {
          "languageId": "python"
        },
        "collapsed": true,
        "outputId": "e3308218-dcb0-4e62-8f5e-6ec7af79f986",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Creating environment from the given name 'Pendulum-v1'\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | -1.24e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 529         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 19          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.028940294 |\n",
            "|    clip_fraction        | 0.221       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.69       |\n",
            "|    explained_variance   | 0.776       |\n",
            "|    learning_rate        | 0.001       |\n",
            "|    loss                 | 11.9        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0196     |\n",
            "|    std                  | 0.971       |\n",
            "|    value_loss           | 34.5        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | -1.03e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 504         |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 40          |\n",
            "|    total_timesteps      | 20480       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021957677 |\n",
            "|    clip_fraction        | 0.194       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.36       |\n",
            "|    explained_variance   | 0.943       |\n",
            "|    learning_rate        | 0.001       |\n",
            "|    loss                 | 8.39        |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.0313     |\n",
            "|    std                  | 0.553       |\n",
            "|    value_loss           | 20.2        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | -613        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 496         |\n",
            "|    iterations           | 15          |\n",
            "|    time_elapsed         | 61          |\n",
            "|    total_timesteps      | 30720       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022074752 |\n",
            "|    clip_fraction        | 0.27        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.75       |\n",
            "|    explained_variance   | 0.994       |\n",
            "|    learning_rate        | 0.001       |\n",
            "|    loss                 | 0.373       |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.013      |\n",
            "|    std                  | 0.352       |\n",
            "|    value_loss           | 2.5         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | -325        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 492         |\n",
            "|    iterations           | 20          |\n",
            "|    time_elapsed         | 83          |\n",
            "|    total_timesteps      | 40960       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.030069264 |\n",
            "|    clip_fraction        | 0.238       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.57       |\n",
            "|    explained_variance   | 0.994       |\n",
            "|    learning_rate        | 0.001       |\n",
            "|    loss                 | 0.722       |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | -0.00794    |\n",
            "|    std                  | 0.304       |\n",
            "|    value_loss           | 1.43        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 200        |\n",
            "|    ep_rew_mean          | -233       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 492        |\n",
            "|    iterations           | 25         |\n",
            "|    time_elapsed         | 103        |\n",
            "|    total_timesteps      | 51200      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.04961852 |\n",
            "|    clip_fraction        | 0.201      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.48      |\n",
            "|    explained_variance   | 0.998      |\n",
            "|    learning_rate        | 0.001      |\n",
            "|    loss                 | 0.109      |\n",
            "|    n_updates            | 240        |\n",
            "|    policy_gradient_loss | 0.00146    |\n",
            "|    std                  | 0.249      |\n",
            "|    value_loss           | 0.417      |\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "tuned_params = {\n",
        "    \"gamma\": 0.9,\n",
        "    \"use_sde\": True,\n",
        "    \"sde_sample_freq\": 4,\n",
        "    \"learning_rate\": 1e-3,\n",
        "}\n",
        "\n",
        "# budget = 10 * budget_pendulum\n",
        "ppo_tuned_model = PPO(\"MlpPolicy\", env_id, seed=1, verbose=1, **tuned_params).learn(50_000, log_interval=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLuxoLxt67xO",
        "outputId": "6776cc94-11ea-46d7-e4fe-d50258bfcd97",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tuned PPO Mean episode reward: -173.08 +/- 124.63\n"
          ]
        }
      ],
      "source": [
        "mean_reward, std_reward = evaluate_policy(ppo_tuned_model, eval_envs, n_eval_episodes=100, deterministic=True)\n",
        "\n",
        "print(f\"Tuned PPO Mean episode reward: {mean_reward:.2f} +/- {std_reward:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2H33u_apWPp5"
      },
      "source": [
        "Note: if you try SAC on the simple MountainCarContinuous environment, you will encounter some issues without tuned hyperparameters: https://github.com/rail-berkeley/softlearning/issues/76\n",
        "\n",
        "Simple environments can be challenging even for SOTA algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vdpPJ04nebx"
      },
      "source": [
        "# Part II: Grad Student Descent\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8PNN9kcgolk"
      },
      "source": [
        "### Challenge (10 minutes): \"Grad Student Descent\"\n",
        "The challenge is to find the best hyperparameters (max performance) for A2C on `CartPole-v1` with a limited budget of 20 000 training steps.\n",
        "\n",
        "\n",
        "Maximum reward: 500 on `CartPole-v1`\n",
        "\n",
        "The hyperparameters should work for different random seeds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "s6aqxsini7H3",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "budget = 20_000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDQ805DBi3KM"
      },
      "source": [
        "#### The baseline: default hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "pyOCKf4Vt-HK",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "eval_envs_cartpole = make_vec_env(\"CartPole-v1\", n_envs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "D1PSNGcsi2dP",
        "vscode": {
          "languageId": "python"
        },
        "collapsed": true,
        "outputId": "ac25e17a-0010-47f1-bf6d-ccfe21c90ef3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Creating environment from the given name 'CartPole-v1'\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 20.2     |\n",
            "|    ep_rew_mean        | 20.2     |\n",
            "| time/                 |          |\n",
            "|    fps                | 369      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 1        |\n",
            "|    total_timesteps    | 500      |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.688   |\n",
            "|    explained_variance | -0.0129  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 99       |\n",
            "|    policy_loss        | 1.95     |\n",
            "|    value_loss         | 8.69     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 19.9     |\n",
            "|    ep_rew_mean        | 19.9     |\n",
            "| time/                 |          |\n",
            "|    fps                | 410      |\n",
            "|    iterations         | 200      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 1000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.693   |\n",
            "|    explained_variance | 0.178    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 199      |\n",
            "|    policy_loss        | -5.49    |\n",
            "|    value_loss         | 88.4     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 19.6     |\n",
            "|    ep_rew_mean        | 19.6     |\n",
            "| time/                 |          |\n",
            "|    fps                | 425      |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 1500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.691   |\n",
            "|    explained_variance | -0.0665  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | 1.81     |\n",
            "|    value_loss         | 7.53     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 19.7      |\n",
            "|    ep_rew_mean        | 19.7      |\n",
            "| time/                 |           |\n",
            "|    fps                | 430       |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 4         |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.69     |\n",
            "|    explained_variance | -0.000389 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | 1.65      |\n",
            "|    value_loss         | 6.52      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 20.7     |\n",
            "|    ep_rew_mean        | 20.7     |\n",
            "| time/                 |          |\n",
            "|    fps                | 413      |\n",
            "|    iterations         | 500      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 2500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.68    |\n",
            "|    explained_variance | -0.178   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 499      |\n",
            "|    policy_loss        | -12.9    |\n",
            "|    value_loss         | 476      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 21.3     |\n",
            "|    ep_rew_mean        | 21.3     |\n",
            "| time/                 |          |\n",
            "|    fps                | 413      |\n",
            "|    iterations         | 600      |\n",
            "|    time_elapsed       | 7        |\n",
            "|    total_timesteps    | 3000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.692   |\n",
            "|    explained_variance | 0.00671  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 599      |\n",
            "|    policy_loss        | 1.46     |\n",
            "|    value_loss         | 5.61     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 22.2     |\n",
            "|    ep_rew_mean        | 22.2     |\n",
            "| time/                 |          |\n",
            "|    fps                | 418      |\n",
            "|    iterations         | 700      |\n",
            "|    time_elapsed       | 8        |\n",
            "|    total_timesteps    | 3500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.693   |\n",
            "|    explained_variance | 0.031    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 699      |\n",
            "|    policy_loss        | 1.33     |\n",
            "|    value_loss         | 4.7      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 23       |\n",
            "|    ep_rew_mean        | 23       |\n",
            "| time/                 |          |\n",
            "|    fps                | 420      |\n",
            "|    iterations         | 800      |\n",
            "|    time_elapsed       | 9        |\n",
            "|    total_timesteps    | 4000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.689   |\n",
            "|    explained_variance | 0.17     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 799      |\n",
            "|    policy_loss        | 1.32     |\n",
            "|    value_loss         | 4.34     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 24.2     |\n",
            "|    ep_rew_mean        | 24.2     |\n",
            "| time/                 |          |\n",
            "|    fps                | 424      |\n",
            "|    iterations         | 900      |\n",
            "|    time_elapsed       | 10       |\n",
            "|    total_timesteps    | 4500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.688   |\n",
            "|    explained_variance | 0.006    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 899      |\n",
            "|    policy_loss        | 1.33     |\n",
            "|    value_loss         | 4.33     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 25.3     |\n",
            "|    ep_rew_mean        | 25.3     |\n",
            "| time/                 |          |\n",
            "|    fps                | 427      |\n",
            "|    iterations         | 1000     |\n",
            "|    time_elapsed       | 11       |\n",
            "|    total_timesteps    | 5000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.625   |\n",
            "|    explained_variance | 0.0399   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 999      |\n",
            "|    policy_loss        | 1.54     |\n",
            "|    value_loss         | 3.87     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 29.1     |\n",
            "|    ep_rew_mean        | 29.1     |\n",
            "| time/                 |          |\n",
            "|    fps                | 430      |\n",
            "|    iterations         | 1100     |\n",
            "|    time_elapsed       | 12       |\n",
            "|    total_timesteps    | 5500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.671   |\n",
            "|    explained_variance | 0.00653  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1099     |\n",
            "|    policy_loss        | 0.939    |\n",
            "|    value_loss         | 3.27     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 32.3     |\n",
            "|    ep_rew_mean        | 32.3     |\n",
            "| time/                 |          |\n",
            "|    fps                | 432      |\n",
            "|    iterations         | 1200     |\n",
            "|    time_elapsed       | 13       |\n",
            "|    total_timesteps    | 6000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.62    |\n",
            "|    explained_variance | 0.0192   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1199     |\n",
            "|    policy_loss        | 0.995    |\n",
            "|    value_loss         | 2.82     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 34.6     |\n",
            "|    ep_rew_mean        | 34.6     |\n",
            "| time/                 |          |\n",
            "|    fps                | 433      |\n",
            "|    iterations         | 1300     |\n",
            "|    time_elapsed       | 14       |\n",
            "|    total_timesteps    | 6500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.607   |\n",
            "|    explained_variance | 0.000247 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1299     |\n",
            "|    policy_loss        | 0.572    |\n",
            "|    value_loss         | 2.51     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 38.1      |\n",
            "|    ep_rew_mean        | 38.1      |\n",
            "| time/                 |           |\n",
            "|    fps                | 435       |\n",
            "|    iterations         | 1400      |\n",
            "|    time_elapsed       | 16        |\n",
            "|    total_timesteps    | 7000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.425    |\n",
            "|    explained_variance | -0.000445 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1399      |\n",
            "|    policy_loss        | 1.1       |\n",
            "|    value_loss         | 2.13      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 42.1      |\n",
            "|    ep_rew_mean        | 42.1      |\n",
            "| time/                 |           |\n",
            "|    fps                | 431       |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 17        |\n",
            "|    total_timesteps    | 7500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.65     |\n",
            "|    explained_variance | -0.000617 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | 0.649     |\n",
            "|    value_loss         | 1.77      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 46       |\n",
            "|    ep_rew_mean        | 46       |\n",
            "| time/                 |          |\n",
            "|    fps                | 428      |\n",
            "|    iterations         | 1600     |\n",
            "|    time_elapsed       | 18       |\n",
            "|    total_timesteps    | 8000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.474   |\n",
            "|    explained_variance | -0.00595 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1599     |\n",
            "|    policy_loss        | 0.85     |\n",
            "|    value_loss         | 1.42     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 48.9     |\n",
            "|    ep_rew_mean        | 48.9     |\n",
            "| time/                 |          |\n",
            "|    fps                | 429      |\n",
            "|    iterations         | 1700     |\n",
            "|    time_elapsed       | 19       |\n",
            "|    total_timesteps    | 8500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.404   |\n",
            "|    explained_variance | 0.000351 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1699     |\n",
            "|    policy_loss        | 0.882    |\n",
            "|    value_loss         | 1.1      |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 55        |\n",
            "|    ep_rew_mean        | 55        |\n",
            "| time/                 |           |\n",
            "|    fps                | 431       |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 20        |\n",
            "|    total_timesteps    | 9000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.534    |\n",
            "|    explained_variance | -0.000594 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | 0.495     |\n",
            "|    value_loss         | 0.823     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 58.8     |\n",
            "|    ep_rew_mean        | 58.8     |\n",
            "| time/                 |          |\n",
            "|    fps                | 432      |\n",
            "|    iterations         | 1900     |\n",
            "|    time_elapsed       | 21       |\n",
            "|    total_timesteps    | 9500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.505   |\n",
            "|    explained_variance | 0.000939 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1899     |\n",
            "|    policy_loss        | 0.295    |\n",
            "|    value_loss         | 0.584    |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 62.8      |\n",
            "|    ep_rew_mean        | 62.8      |\n",
            "| time/                 |           |\n",
            "|    fps                | 433       |\n",
            "|    iterations         | 2000      |\n",
            "|    time_elapsed       | 23        |\n",
            "|    total_timesteps    | 10000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.547    |\n",
            "|    explained_variance | -0.000198 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1999      |\n",
            "|    policy_loss        | 0.271     |\n",
            "|    value_loss         | 0.387     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 67.4      |\n",
            "|    ep_rew_mean        | 67.4      |\n",
            "| time/                 |           |\n",
            "|    fps                | 434       |\n",
            "|    iterations         | 2100      |\n",
            "|    time_elapsed       | 24        |\n",
            "|    total_timesteps    | 10500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.557    |\n",
            "|    explained_variance | -0.000216 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2099      |\n",
            "|    policy_loss        | 0.22      |\n",
            "|    value_loss         | 0.225     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 72.6      |\n",
            "|    ep_rew_mean        | 72.6      |\n",
            "| time/                 |           |\n",
            "|    fps                | 435       |\n",
            "|    iterations         | 2200      |\n",
            "|    time_elapsed       | 25        |\n",
            "|    total_timesteps    | 11000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.585    |\n",
            "|    explained_variance | -5.96e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2199      |\n",
            "|    policy_loss        | 0.104     |\n",
            "|    value_loss         | 0.109     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 77.2     |\n",
            "|    ep_rew_mean        | 77.2     |\n",
            "| time/                 |          |\n",
            "|    fps                | 436      |\n",
            "|    iterations         | 2300     |\n",
            "|    time_elapsed       | 26       |\n",
            "|    total_timesteps    | 11500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.416   |\n",
            "|    explained_variance | 0.000152 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2299     |\n",
            "|    policy_loss        | 0.162    |\n",
            "|    value_loss         | 0.0354   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 81.8     |\n",
            "|    ep_rew_mean        | 81.8     |\n",
            "| time/                 |          |\n",
            "|    fps                | 437      |\n",
            "|    iterations         | 2400     |\n",
            "|    time_elapsed       | 27       |\n",
            "|    total_timesteps    | 12000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.532   |\n",
            "|    explained_variance | 0.000918 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2399     |\n",
            "|    policy_loss        | 0.0178   |\n",
            "|    value_loss         | 0.00197  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 84.5     |\n",
            "|    ep_rew_mean        | 84.5     |\n",
            "| time/                 |          |\n",
            "|    fps                | 436      |\n",
            "|    iterations         | 2500     |\n",
            "|    time_elapsed       | 28       |\n",
            "|    total_timesteps    | 12500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.56    |\n",
            "|    explained_variance | -0.00501 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2499     |\n",
            "|    policy_loss        | 0.000929 |\n",
            "|    value_loss         | 9.32e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 91.1     |\n",
            "|    ep_rew_mean        | 91.1     |\n",
            "| time/                 |          |\n",
            "|    fps                | 432      |\n",
            "|    iterations         | 2600     |\n",
            "|    time_elapsed       | 30       |\n",
            "|    total_timesteps    | 13000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.51    |\n",
            "|    explained_variance | -0.0151  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2599     |\n",
            "|    policy_loss        | 0.00124  |\n",
            "|    value_loss         | 5.97e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 94.6     |\n",
            "|    ep_rew_mean        | 94.6     |\n",
            "| time/                 |          |\n",
            "|    fps                | 433      |\n",
            "|    iterations         | 2700     |\n",
            "|    time_elapsed       | 31       |\n",
            "|    total_timesteps    | 13500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.368   |\n",
            "|    explained_variance | -0.0329  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2699     |\n",
            "|    policy_loss        | 0.00071  |\n",
            "|    value_loss         | 1.2e-06  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 98.8     |\n",
            "|    ep_rew_mean        | 98.8     |\n",
            "| time/                 |          |\n",
            "|    fps                | 434      |\n",
            "|    iterations         | 2800     |\n",
            "|    time_elapsed       | 32       |\n",
            "|    total_timesteps    | 14000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.544   |\n",
            "|    explained_variance | 0.3      |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2799     |\n",
            "|    policy_loss        | 0.000179 |\n",
            "|    value_loss         | 1.54e-07 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 104      |\n",
            "|    ep_rew_mean        | 104      |\n",
            "| time/                 |          |\n",
            "|    fps                | 435      |\n",
            "|    iterations         | 2900     |\n",
            "|    time_elapsed       | 33       |\n",
            "|    total_timesteps    | 14500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.469   |\n",
            "|    explained_variance | 0.122    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2899     |\n",
            "|    policy_loss        | 0.000126 |\n",
            "|    value_loss         | 2.27e-07 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 107      |\n",
            "|    ep_rew_mean        | 107      |\n",
            "| time/                 |          |\n",
            "|    fps                | 435      |\n",
            "|    iterations         | 3000     |\n",
            "|    time_elapsed       | 34       |\n",
            "|    total_timesteps    | 15000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.533   |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2999     |\n",
            "|    policy_loss        | 5.19e-06 |\n",
            "|    value_loss         | 3.96e-10 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 111       |\n",
            "|    ep_rew_mean        | 111       |\n",
            "| time/                 |           |\n",
            "|    fps                | 436       |\n",
            "|    iterations         | 3100      |\n",
            "|    time_elapsed       | 35        |\n",
            "|    total_timesteps    | 15500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.423    |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3099      |\n",
            "|    policy_loss        | -2.08e-06 |\n",
            "|    value_loss         | 8.15e-11  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 114      |\n",
            "|    ep_rew_mean        | 114      |\n",
            "| time/                 |          |\n",
            "|    fps                | 436      |\n",
            "|    iterations         | 3200     |\n",
            "|    time_elapsed       | 36       |\n",
            "|    total_timesteps    | 16000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.435   |\n",
            "|    explained_variance | -5.87    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3199     |\n",
            "|    policy_loss        | 1.01e-05 |\n",
            "|    value_loss         | 2.22e-09 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 119      |\n",
            "|    ep_rew_mean        | 119      |\n",
            "| time/                 |          |\n",
            "|    fps                | 437      |\n",
            "|    iterations         | 3300     |\n",
            "|    time_elapsed       | 37       |\n",
            "|    total_timesteps    | 16500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.424   |\n",
            "|    explained_variance | -5.12    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3299     |\n",
            "|    policy_loss        | 7.53e-06 |\n",
            "|    value_loss         | 1.98e-09 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 124      |\n",
            "|    ep_rew_mean        | 124      |\n",
            "| time/                 |          |\n",
            "|    fps                | 437      |\n",
            "|    iterations         | 3400     |\n",
            "|    time_elapsed       | 38       |\n",
            "|    total_timesteps    | 17000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.415   |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3399     |\n",
            "|    policy_loss        | 2.68e-06 |\n",
            "|    value_loss         | 5.01e-10 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 129      |\n",
            "|    ep_rew_mean        | 129      |\n",
            "| time/                 |          |\n",
            "|    fps                | 437      |\n",
            "|    iterations         | 3500     |\n",
            "|    time_elapsed       | 39       |\n",
            "|    total_timesteps    | 17500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.536   |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3499     |\n",
            "|    policy_loss        | 8.75e-06 |\n",
            "|    value_loss         | 1.8e-09  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 134      |\n",
            "|    ep_rew_mean        | 134      |\n",
            "| time/                 |          |\n",
            "|    fps                | 435      |\n",
            "|    iterations         | 3600     |\n",
            "|    time_elapsed       | 41       |\n",
            "|    total_timesteps    | 18000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.41    |\n",
            "|    explained_variance | -0.177   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3599     |\n",
            "|    policy_loss        | 0.000102 |\n",
            "|    value_loss         | 6.97e-08 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 138       |\n",
            "|    ep_rew_mean        | 138       |\n",
            "| time/                 |           |\n",
            "|    fps                | 434       |\n",
            "|    iterations         | 3700      |\n",
            "|    time_elapsed       | 42        |\n",
            "|    total_timesteps    | 18500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.386    |\n",
            "|    explained_variance | -0.0601   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3699      |\n",
            "|    policy_loss        | -0.000465 |\n",
            "|    value_loss         | 8.96e-07  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 143      |\n",
            "|    ep_rew_mean        | 143      |\n",
            "| time/                 |          |\n",
            "|    fps                | 435      |\n",
            "|    iterations         | 3800     |\n",
            "|    time_elapsed       | 43       |\n",
            "|    total_timesteps    | 19000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.497   |\n",
            "|    explained_variance | -0.265   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3799     |\n",
            "|    policy_loss        | -0.00011 |\n",
            "|    value_loss         | 1.26e-07 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 150      |\n",
            "|    ep_rew_mean        | 150      |\n",
            "| time/                 |          |\n",
            "|    fps                | 436      |\n",
            "|    iterations         | 3900     |\n",
            "|    time_elapsed       | 44       |\n",
            "|    total_timesteps    | 19500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.464   |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3899     |\n",
            "|    policy_loss        | 1.25e-05 |\n",
            "|    value_loss         | 1.06e-09 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 156      |\n",
            "|    ep_rew_mean        | 156      |\n",
            "| time/                 |          |\n",
            "|    fps                | 436      |\n",
            "|    iterations         | 4000     |\n",
            "|    time_elapsed       | 45       |\n",
            "|    total_timesteps    | 20000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.269   |\n",
            "|    explained_variance | 0.0727   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3999     |\n",
            "|    policy_loss        | 0.00132  |\n",
            "|    value_loss         | 3.1e-06  |\n",
            "------------------------------------\n"
          ]
        }
      ],
      "source": [
        "model = A2C(\"MlpPolicy\", \"CartPole-v1\", seed=8, verbose=1).learn(budget)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d3X0G0ng2OE",
        "outputId": "d1dbd505-871b-49a8-cc45-54e3de93f554",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_reward:442.68 +/- 86.44\n"
          ]
        }
      ],
      "source": [
        "mean_reward, std_reward = evaluate_policy(model, eval_envs_cartpole, n_eval_episodes=50, deterministic=True)\n",
        "\n",
        "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-fi1-oKnUI2"
      },
      "source": [
        "**Your goal is to beat that baseline and get closer to the optimal score of 500**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvq8zizok1X_"
      },
      "source": [
        "Time to tune!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "UaqCCH4gkRH_",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "uDUfeZcyjPKS",
        "vscode": {
          "languageId": "python"
        },
        "collapsed": true,
        "outputId": "2a445934-4d79-4772-8e31-a9a255d2fcc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax. Perhaps you forgot a comma? (ipython-input-3066477858.py, line 11)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-3066477858.py\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    gamma = trial.suggest_float(\"gamma\", 0.9, 0.99999, log=True)\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
          ]
        }
      ],
      "source": [
        "policy_kwargs = dict(\n",
        "    net_arch=[\n",
        "      dict(vf=[64, 64], pi=[64, 64]), # network architectures for actor/critic\n",
        "    ],\n",
        "    activation_fn=nn.Tanh,\n",
        ")\n",
        "\n",
        "hyperparams = dict(\n",
        "    n_steps=5, # number of steps to collect data before updating policy\n",
        "    learning_rate=7e-4,\n",
        "    gamma=0.99, # discount factor\n",
        "    max_grad_norm=0.5, # The maximum value for the gradient clipping\n",
        "    ent_coef=0.0, # Entropy coefficient for the loss calculation\n",
        ")\n",
        "\n",
        "model = A2C(\"MlpPolicy\", \"CartPole-v1\", seed=8, verbose=1, **hyperparams).learn(budget)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "0_o-Aup-9S_D",
        "outputId": "966a4022-5145-4f89-9651-1bc8b76faa44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_reward:112.88 +/- 7.87\n"
          ]
        }
      ],
      "source": [
        "mean_reward, std_reward = evaluate_policy(model, eval_envs_cartpole, n_eval_episodes=50, deterministic=True)\n",
        "\n",
        "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iL_G9DurUV75"
      },
      "source": [
        "Hint - Recommended Hyperparameter Range\n",
        "\n",
        "```python\n",
        "gamma = trial.suggest_float(\"gamma\", 0.9, 0.99999, log=True)\n",
        "max_grad_norm = trial.suggest_float(\"max_grad_norm\", 0.3, 5.0, log=True)\n",
        "# from 2**3 = 8 to 2**10 = 1024\n",
        "n_steps = 2 ** trial.suggest_int(\"exponent_n_steps\", 3, 10)\n",
        "learning_rate = trial.suggest_float(\"lr\", 1e-5, 1, log=True)\n",
        "ent_coef = trial.suggest_float(\"ent_coef\", 0.00000001, 0.1, log=True)\n",
        "# net_arch tiny: {\"pi\": [64], \"vf\": [64]}\n",
        "# net_arch default: {\"pi\": [64, 64], \"vf\": [64, 64]}\n",
        "# activation_fn = nn.Tanh / nn.ReLU\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwFOp0j-ga-_"
      },
      "source": [
        "# Part III: Automatic Hyperparameter Tuning\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88x7wMyyud5p"
      },
      "source": [
        "In this part we will create a script that allows to search for the best hyperparameters automatically."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auwR-30IvHeY"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "VM6tUr-yuekR",
        "vscode": {
          "languageId": "python"
        },
        "outputId": "56b65e44-4b61-4443-fd3c-74cd3e8ab85e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "from optuna.pruners import MedianPruner\n",
        "from optuna.samplers import TPESampler\n",
        "from optuna.visualization import plot_optimization_history, plot_param_importances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQVfmM1dzA1d"
      },
      "source": [
        "### Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "yyBTVcAGzCRk",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "N_TRIALS = 100  # Maximum number of trials\n",
        "N_JOBS = 1 # Number of jobs to run in parallel\n",
        "N_STARTUP_TRIALS = 5  # Stop random sampling after N_STARTUP_TRIALS\n",
        "N_EVALUATIONS = 2  # Number of evaluations during the training\n",
        "N_TIMESTEPS = int(2e4)  # Training budget\n",
        "EVAL_FREQ = int(N_TIMESTEPS / N_EVALUATIONS)\n",
        "N_EVAL_ENVS = 5\n",
        "N_EVAL_EPISODES = 10\n",
        "TIMEOUT = int(60 * 15)  # 15 minutes\n",
        "\n",
        "ENV_ID = \"CartPole-v1\"\n",
        "\n",
        "DEFAULT_HYPERPARAMS = {\n",
        "    \"policy\": \"MlpPolicy\",\n",
        "    \"env\": ENV_ID,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25HgcDYzvJ0b"
      },
      "source": [
        "### Exercise (5 minutes): Define the search space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "KXo8AwGAvN8Q",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from typing import Any, Dict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def sample_a2c_params(trial: optuna.Trial) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Sampler for A2C hyperparameters.\n",
        "\n",
        "    :param trial: Optuna trial object\n",
        "    :return: The sampled hyperparameters for the given trial.\n",
        "    \"\"\"\n",
        "    # Discount factor between 0.9 and 0.9999\n",
        "    gamma = 1.0 - trial.suggest_float(\"gamma\", 0.0001, 0.1, log=True)\n",
        "    max_grad_norm = trial.suggest_float(\"max_grad_norm\", 0.3, 5.0, log=True)\n",
        "    # 8, 16, 32, ... 1024\n",
        "    n_steps = 2 ** trial.suggest_int(\"exponent_n_steps\", 3, 10)\n",
        "\n",
        "    ### YOUR CODE HERE\n",
        "    # TODO:\n",
        "\n",
        "    # 1. Define the learning rate search space [1e-5, 1] (log)\n",
        "    learning_rate = trial.suggest_float(\"lr\", 1e-5, 1, log=True)\n",
        "\n",
        "    # 2. Define the network architecture search space [\"tiny\", \"small\"]\n",
        "    # 这里只选择字符串标签，下方的代码会将标签转换为具体的字典结构\n",
        "    net_arch = trial.suggest_categorical(\"net_arch\", [\"tiny\", \"small\"])\n",
        "\n",
        "    # 3. Define the activation function search space [\"tanh\", \"relu\"]\n",
        "    # 同样只选择字符串标签，下方代码会将 \"tanh\" 映射为 nn.Tanh\n",
        "    activation_fn = trial.suggest_categorical(\"activation_fn\", [\"tanh\", \"relu\"])\n",
        "\n",
        "    ### END OF YOUR CODE\n",
        "\n",
        "    # Display true values\n",
        "    trial.set_user_attr(\"gamma_\", gamma)\n",
        "    trial.set_user_attr(\"n_steps\", n_steps)\n",
        "\n",
        "    net_arch = [\n",
        "        {\"pi\": [64], \"vf\": [64]}\n",
        "        if net_arch == \"tiny\"\n",
        "        else {\"pi\": [64, 64], \"vf\": [64, 64]}\n",
        "    ]\n",
        "\n",
        "    activation_fn = {\"tanh\": nn.Tanh, \"relu\": nn.ReLU}[activation_fn]\n",
        "\n",
        "    return {\n",
        "        \"n_steps\": n_steps,\n",
        "        \"gamma\": gamma,\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"max_grad_norm\": max_grad_norm,\n",
        "        \"policy_kwargs\": {\n",
        "            \"net_arch\": net_arch,\n",
        "            \"activation_fn\": activation_fn,\n",
        "        },\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iybymNiJxNu7"
      },
      "source": [
        "### Define the objective function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJY8Z8tuxai7"
      },
      "source": [
        "First we define a custom callback to report the results of periodic evaluations to Optuna:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "U5ijWTPzxSmd",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "\n",
        "class TrialEvalCallback(EvalCallback):\n",
        "    \"\"\"\n",
        "    Callback used for evaluating and reporting a trial.\n",
        "\n",
        "    :param eval_env: Evaluation environement\n",
        "    :param trial: Optuna trial object\n",
        "    :param n_eval_episodes: Number of evaluation episodes\n",
        "    :param eval_freq:   Evaluate the agent every ``eval_freq`` call of the callback.\n",
        "    :param deterministic: Whether the evaluation should\n",
        "        use a stochastic or deterministic policy.\n",
        "    :param verbose:\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        eval_env: gym.Env,\n",
        "        trial: optuna.Trial,\n",
        "        n_eval_episodes: int = 5,\n",
        "        eval_freq: int = 10000,\n",
        "        deterministic: bool = True,\n",
        "        verbose: int = 0,\n",
        "    ):\n",
        "\n",
        "        super().__init__(\n",
        "            eval_env=eval_env,\n",
        "            n_eval_episodes=n_eval_episodes,\n",
        "            eval_freq=eval_freq,\n",
        "            deterministic=deterministic,\n",
        "            verbose=verbose,\n",
        "        )\n",
        "        self.trial = trial\n",
        "        self.eval_idx = 0\n",
        "        self.is_pruned = False\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        if self.eval_freq > 0 and self.n_calls % self.eval_freq == 0:\n",
        "            # Evaluate policy (done in the parent class)\n",
        "            super()._on_step()\n",
        "            self.eval_idx += 1\n",
        "            # Send report to Optuna\n",
        "            self.trial.report(self.last_mean_reward, self.eval_idx)\n",
        "            # Prune trial if need\n",
        "            if self.trial.should_prune():\n",
        "                self.is_pruned = True\n",
        "                return False\n",
        "        return True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cHNM_cFO3vs"
      },
      "source": [
        "### Exercise (10 minutes): Define the objective function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76voi9AXxlCq"
      },
      "source": [
        "Then we define the objective function that is in charge of sampling hyperparameters, creating the model and then returning the result to Optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "E0yEokTDxhrC",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def objective(trial: optuna.Trial) -> float:\n",
        "    kwargs = DEFAULT_HYPERPARAMS.copy()\n",
        "\n",
        "    # 1. 采样超参数并更新 kwargs\n",
        "    # 注意：确保 sample_a2c_params 函数里也没有 ...\n",
        "    kwargs.update(sample_a2c_params(trial))\n",
        "\n",
        "    # 创建训练环境（A2C 可以在 CPU 上跑得更快，如果不用 CNN）\n",
        "    # 建议加上 device='cpu' 来消除那个 Warning\n",
        "    kwargs[\"env\"] = make_vec_env(ENV_ID, n_envs=4)\n",
        "\n",
        "    # 创建模型\n",
        "    # device=\"cpu\" 是为了解决你报错里的 UserWarning，对于小的 MLP 网络，CPU 往往比 GPU 快\n",
        "    model = A2C(**kwargs)\n",
        "\n",
        "    # 2. 创建独立的评估环境\n",
        "    eval_envs = make_vec_env(ENV_ID, n_envs=N_EVAL_ENVS)\n",
        "\n",
        "    # 3. 创建回调函数\n",
        "    # 【重点检查这里】：确保参数列表里没有 ...，也没有 callback_on_new_best=...\n",
        "    eval_callback = TrialEvalCallback(\n",
        "        eval_envs,\n",
        "        trial,\n",
        "        n_eval_episodes=N_EVAL_EPISODES,\n",
        "        eval_freq=EVAL_FREQ,\n",
        "        deterministic=True\n",
        "    )\n",
        "\n",
        "    nan_encountered = False\n",
        "    try:\n",
        "        # 开始训练\n",
        "        model.learn(N_TIMESTEPS, callback=eval_callback)\n",
        "    except AssertionError as e:\n",
        "        print(e)\n",
        "        nan_encountered = True\n",
        "    finally:\n",
        "        model.env.close()\n",
        "        eval_envs.close()\n",
        "\n",
        "    if nan_encountered:\n",
        "        return float(\"nan\")\n",
        "\n",
        "    if eval_callback.is_pruned:\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    return eval_callback.last_mean_reward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMFLu_M0ymzj"
      },
      "source": [
        "### The optimization loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "4UU17YpjymPr",
        "vscode": {
          "languageId": "python"
        },
        "collapsed": true,
        "outputId": "1f65b7d2-a50e-43bf-ef34-a6dac07a433d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-22 03:40:09,861] A new study created in memory with name: no-name-bca338a0-fe07-4399-9ebc-edb6cc5bb36a\n",
            "/usr/local/lib/python3.12/dist-packages/stable_baselines3/common/policies.py:486: UserWarning:\n",
            "\n",
            "As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
            "\n",
            "/usr/local/lib/python3.12/dist-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning:\n",
            "\n",
            "You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "\n",
            "[I 2025-12-22 03:40:18,523] Trial 0 finished with value: -inf and parameters: {'gamma': 0.0005154292404657294, 'max_grad_norm': 0.5837153849558163, 'exponent_n_steps': 4, 'lr': 0.0011194363508517117, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:40:26,000] Trial 1 finished with value: -inf and parameters: {'gamma': 0.008651362784122991, 'max_grad_norm': 2.3719517613019376, 'exponent_n_steps': 7, 'lr': 3.0105181446270197e-05, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:40:33,348] Trial 2 finished with value: -inf and parameters: {'gamma': 0.022839129205696886, 'max_grad_norm': 3.1427156563759717, 'exponent_n_steps': 8, 'lr': 1.9947363301435055e-05, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:40:41,782] Trial 3 finished with value: -inf and parameters: {'gamma': 0.00011863351431291268, 'max_grad_norm': 1.9654229166662074, 'exponent_n_steps': 4, 'lr': 0.0016599135148588986, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:40:50,047] Trial 4 finished with value: -inf and parameters: {'gamma': 0.004935556229498878, 'max_grad_norm': 1.336889403998605, 'exponent_n_steps': 4, 'lr': 0.0005142919094264466, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:41:00,599] Trial 5 finished with value: -inf and parameters: {'gamma': 0.00030711414372146196, 'max_grad_norm': 0.37118944795071207, 'exponent_n_steps': 3, 'lr': 0.5033188602334091, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:41:07,973] Trial 6 finished with value: -inf and parameters: {'gamma': 0.000670650440762768, 'max_grad_norm': 0.5026442849259452, 'exponent_n_steps': 10, 'lr': 0.18689517412082218, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:41:15,340] Trial 7 finished with value: -inf and parameters: {'gamma': 0.0009073904329558355, 'max_grad_norm': 0.7637235635815393, 'exponent_n_steps': 5, 'lr': 0.010895704231861722, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:41:23,428] Trial 8 finished with value: -inf and parameters: {'gamma': 0.0022095583405098017, 'max_grad_norm': 0.8875705376522307, 'exponent_n_steps': 6, 'lr': 0.022656695191354975, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:41:33,319] Trial 9 finished with value: -inf and parameters: {'gamma': 0.04281838900837193, 'max_grad_norm': 0.5570424574531782, 'exponent_n_steps': 3, 'lr': 0.00025971177485174346, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:41:40,964] Trial 10 finished with value: -inf and parameters: {'gamma': 0.00018594134733673532, 'max_grad_norm': 4.573787868259407, 'exponent_n_steps': 9, 'lr': 0.00011677752632908788, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:41:48,390] Trial 11 finished with value: -inf and parameters: {'gamma': 0.006142152620996897, 'max_grad_norm': 1.887176290662338, 'exponent_n_steps': 7, 'lr': 1.2001226076853631e-05, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:41:56,422] Trial 12 finished with value: -inf and parameters: {'gamma': 0.012791913859475321, 'max_grad_norm': 2.4852845514717212, 'exponent_n_steps': 6, 'lr': 7.52510051052956e-05, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:42:04,091] Trial 13 finished with value: -inf and parameters: {'gamma': 0.08655086523604423, 'max_grad_norm': 1.1531131906747483, 'exponent_n_steps': 7, 'lr': 0.0017589569148918278, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:42:11,668] Trial 14 finished with value: -inf and parameters: {'gamma': 0.0015841305803739596, 'max_grad_norm': 0.3360895536647565, 'exponent_n_steps': 5, 'lr': 0.03138358662209366, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:42:19,437] Trial 15 finished with value: -inf and parameters: {'gamma': 0.0005673666207857468, 'max_grad_norm': 4.6284333916987626, 'exponent_n_steps': 8, 'lr': 4.820130647231681e-05, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:42:27,623] Trial 16 finished with value: -inf and parameters: {'gamma': 0.012592917222376427, 'max_grad_norm': 1.4462447253707247, 'exponent_n_steps': 5, 'lr': 0.0005267544657928635, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:42:34,663] Trial 17 finished with value: -inf and parameters: {'gamma': 0.0032607550710400915, 'max_grad_norm': 0.7351367285570749, 'exponent_n_steps': 8, 'lr': 0.004797537867559197, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:42:43,686] Trial 18 finished with value: -inf and parameters: {'gamma': 0.00039321651891353464, 'max_grad_norm': 3.279413016748073, 'exponent_n_steps': 4, 'lr': 0.0003204830591166751, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:42:50,888] Trial 19 finished with value: -inf and parameters: {'gamma': 0.0014256106802632443, 'max_grad_norm': 0.48599301548290674, 'exponent_n_steps': 6, 'lr': 0.0809868129330098, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:42:57,977] Trial 20 finished with value: -inf and parameters: {'gamma': 0.008674544298638499, 'max_grad_norm': 1.053705016752748, 'exponent_n_steps': 10, 'lr': 3.2429218726657016e-05, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:43:05,298] Trial 21 finished with value: -inf and parameters: {'gamma': 0.025514183341998387, 'max_grad_norm': 2.770045538742052, 'exponent_n_steps': 8, 'lr': 1.063082649712845e-05, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:43:12,070] Trial 22 finished with value: -inf and parameters: {'gamma': 0.030895956607880557, 'max_grad_norm': 3.5120568584178633, 'exponent_n_steps': 9, 'lr': 2.2103102770830025e-05, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:43:19,520] Trial 23 finished with value: -inf and parameters: {'gamma': 0.017769285759749662, 'max_grad_norm': 1.8967358413157032, 'exponent_n_steps': 7, 'lr': 7.573403291615761e-05, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:43:26,584] Trial 24 finished with value: -inf and parameters: {'gamma': 0.059694140271892356, 'max_grad_norm': 2.65557845233675, 'exponent_n_steps': 9, 'lr': 0.00015912486232368665, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:43:33,651] Trial 25 finished with value: -inf and parameters: {'gamma': 0.004126934642022248, 'max_grad_norm': 1.5955536043627931, 'exponent_n_steps': 8, 'lr': 0.001524599748708436, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:43:41,587] Trial 26 finished with value: -inf and parameters: {'gamma': 0.008308053504606354, 'max_grad_norm': 3.690407190192311, 'exponent_n_steps': 7, 'lr': 2.9790883201194936e-05, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:43:48,578] Trial 27 finished with value: -inf and parameters: {'gamma': 0.018652923531072074, 'max_grad_norm': 2.279108716497383, 'exponent_n_steps': 6, 'lr': 0.004242047095887726, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:43:56,207] Trial 28 finished with value: -inf and parameters: {'gamma': 0.002732758586635626, 'max_grad_norm': 3.930153912988352, 'exponent_n_steps': 9, 'lr': 0.0009031720996205556, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:44:04,666] Trial 29 finished with value: -inf and parameters: {'gamma': 0.0001478383660176451, 'max_grad_norm': 3.074542295166714, 'exponent_n_steps': 4, 'lr': 0.00015956355033040694, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:44:11,464] Trial 30 finished with value: -inf and parameters: {'gamma': 0.0013805562468541402, 'max_grad_norm': 2.1436883657093313, 'exponent_n_steps': 8, 'lr': 1.8808937065150654e-05, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:44:19,994] Trial 31 finished with value: -inf and parameters: {'gamma': 0.00010318376565058276, 'max_grad_norm': 1.785458665236716, 'exponent_n_steps': 4, 'lr': 0.00866997927059306, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:44:29,850] Trial 32 finished with value: -inf and parameters: {'gamma': 0.00032415688662503205, 'max_grad_norm': 1.2699549745081298, 'exponent_n_steps': 3, 'lr': 0.0007223227667308807, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:44:37,747] Trial 33 finished with value: -inf and parameters: {'gamma': 0.0002055479454141901, 'max_grad_norm': 0.4237660473099056, 'exponent_n_steps': 5, 'lr': 0.0024673526734456737, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:44:47,267] Trial 34 finished with value: -inf and parameters: {'gamma': 0.0059233250686385784, 'max_grad_norm': 1.49949675950381, 'exponent_n_steps': 3, 'lr': 0.8939554872361752, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:44:55,704] Trial 35 finished with value: -inf and parameters: {'gamma': 0.00010020985084984201, 'max_grad_norm': 0.6428036975460198, 'exponent_n_steps': 4, 'lr': 0.0003116884267386611, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:45:03,589] Trial 36 finished with value: -inf and parameters: {'gamma': 0.0006791532813939636, 'max_grad_norm': 0.9425283739595255, 'exponent_n_steps': 5, 'lr': 0.1950342414866416, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:45:11,078] Trial 37 finished with value: -inf and parameters: {'gamma': 0.00041516968120694405, 'max_grad_norm': 2.184818921829921, 'exponent_n_steps': 7, 'lr': 0.02110929378835302, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:45:20,846] Trial 38 finished with value: -inf and parameters: {'gamma': 0.00023423007139303196, 'max_grad_norm': 2.906332338487611, 'exponent_n_steps': 3, 'lr': 5.837281647682349e-05, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:45:28,672] Trial 39 finished with value: -inf and parameters: {'gamma': 0.0009156005842456672, 'max_grad_norm': 0.30687504188914194, 'exponent_n_steps': 6, 'lr': 0.0010195951754887452, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:45:37,168] Trial 40 finished with value: -inf and parameters: {'gamma': 0.04694136842464451, 'max_grad_norm': 4.007266846471164, 'exponent_n_steps': 4, 'lr': 0.0001300389726786551, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:45:44,491] Trial 41 finished with value: -inf and parameters: {'gamma': 0.005029851538757699, 'max_grad_norm': 1.3341861761560927, 'exponent_n_steps': 5, 'lr': 0.0005049635886256091, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:45:52,820] Trial 42 finished with value: -inf and parameters: {'gamma': 0.009472688943004116, 'max_grad_norm': 1.7610525081525734, 'exponent_n_steps': 4, 'lr': 0.006679259075071502, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:46:03,092] Trial 43 finished with value: -inf and parameters: {'gamma': 0.0019210202688662483, 'max_grad_norm': 0.8177657856613867, 'exponent_n_steps': 3, 'lr': 0.001982531283982799, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:46:10,350] Trial 44 finished with value: -inf and parameters: {'gamma': 0.015984771354995146, 'max_grad_norm': 1.0436100095900915, 'exponent_n_steps': 5, 'lr': 0.01835088923319931, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:46:18,104] Trial 45 finished with value: -inf and parameters: {'gamma': 0.0036798883543807705, 'max_grad_norm': 2.3570331267567974, 'exponent_n_steps': 7, 'lr': 0.0002274651395202601, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:46:26,489] Trial 46 finished with value: -inf and parameters: {'gamma': 0.026000454158211946, 'max_grad_norm': 2.0595078534060702, 'exponent_n_steps': 4, 'lr': 8.231569486779881e-05, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:46:33,525] Trial 47 finished with value: -inf and parameters: {'gamma': 0.000882456443046225, 'max_grad_norm': 0.6198228283725429, 'exponent_n_steps': 6, 'lr': 0.0004681856242938425, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:46:43,934] Trial 48 finished with value: -inf and parameters: {'gamma': 0.012904221665621897, 'max_grad_norm': 1.6228397152919265, 'exponent_n_steps': 3, 'lr': 0.0013200004638789626, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:46:51,118] Trial 49 finished with value: -inf and parameters: {'gamma': 0.010218300517956557, 'max_grad_norm': 1.1400846361040993, 'exponent_n_steps': 8, 'lr': 0.00366913698099622, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:46:58,564] Trial 50 finished with value: -inf and parameters: {'gamma': 0.002164507557084388, 'max_grad_norm': 2.5778651516806854, 'exponent_n_steps': 9, 'lr': 1.5065570776538788e-05, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:47:08,742] Trial 51 finished with value: -inf and parameters: {'gamma': 0.00014611931569770523, 'max_grad_norm': 0.3878646050203771, 'exponent_n_steps': 3, 'lr': 0.0545016340135108, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:47:17,741] Trial 52 finished with value: -inf and parameters: {'gamma': 0.0002574557163697489, 'max_grad_norm': 0.5016804240898619, 'exponent_n_steps': 4, 'lr': 4.583643984868075e-05, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:47:28,232] Trial 53 finished with value: -inf and parameters: {'gamma': 0.0005069241199987609, 'max_grad_norm': 0.3802200194693183, 'exponent_n_steps': 3, 'lr': 0.19973361641767948, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:47:37,242] Trial 54 finished with value: -inf and parameters: {'gamma': 0.00015172006957545634, 'max_grad_norm': 0.7313958394461232, 'exponent_n_steps': 4, 'lr': 0.014365373053308827, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:47:44,146] Trial 55 finished with value: -inf and parameters: {'gamma': 0.006950119935928595, 'max_grad_norm': 4.8721903807792915, 'exponent_n_steps': 7, 'lr': 3.305195902341583e-05, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:47:52,548] Trial 56 finished with value: -inf and parameters: {'gamma': 0.000319014350213382, 'max_grad_norm': 0.46258109029246747, 'exponent_n_steps': 5, 'lr': 0.3199252846482643, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:47:59,829] Trial 57 finished with value: -inf and parameters: {'gamma': 0.0045396305020734525, 'max_grad_norm': 0.5899652857246812, 'exponent_n_steps': 8, 'lr': 0.0023022284629369656, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:48:07,970] Trial 58 finished with value: -inf and parameters: {'gamma': 0.0029679228672932906, 'max_grad_norm': 3.284602660465444, 'exponent_n_steps': 4, 'lr': 0.036279363082527605, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:48:15,833] Trial 59 finished with value: -inf and parameters: {'gamma': 0.07256902008501585, 'max_grad_norm': 0.5453367245349592, 'exponent_n_steps': 6, 'lr': 1.1320314367802752e-05, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:48:25,528] Trial 60 finished with value: -inf and parameters: {'gamma': 0.03745074503625135, 'max_grad_norm': 1.9639747295116765, 'exponent_n_steps': 3, 'lr': 0.00021697581393421872, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:48:32,601] Trial 61 finished with value: -inf and parameters: {'gamma': 0.0010273895071643397, 'max_grad_norm': 0.3611118646506266, 'exponent_n_steps': 10, 'lr': 0.2904668248166579, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:48:39,592] Trial 62 finished with value: -inf and parameters: {'gamma': 0.0006922944062244234, 'max_grad_norm': 0.3085640860403116, 'exponent_n_steps': 10, 'lr': 0.8156281286750349, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:48:46,713] Trial 63 finished with value: -inf and parameters: {'gamma': 0.0002791293301636258, 'max_grad_norm': 0.41999130550826336, 'exponent_n_steps': 10, 'lr': 0.11961277718620485, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:48:53,466] Trial 64 finished with value: -inf and parameters: {'gamma': 0.0005043558886429515, 'max_grad_norm': 0.6706112605360233, 'exponent_n_steps': 9, 'lr': 0.6164236786786891, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:49:00,714] Trial 65 finished with value: -inf and parameters: {'gamma': 0.00038945467787979886, 'max_grad_norm': 1.3935127722638527, 'exponent_n_steps': 8, 'lr': 0.0006871265615788997, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:49:07,703] Trial 66 finished with value: -inf and parameters: {'gamma': 0.00017477935166901914, 'max_grad_norm': 0.5425442920665052, 'exponent_n_steps': 9, 'lr': 0.4984471764642838, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:49:15,259] Trial 67 finished with value: -inf and parameters: {'gamma': 0.001628770243819481, 'max_grad_norm': 0.3393784154038008, 'exponent_n_steps': 6, 'lr': 0.0069326056180727645, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:49:23,766] Trial 68 finished with value: -inf and parameters: {'gamma': 0.00011574953057077905, 'max_grad_norm': 2.7758120046238424, 'exponent_n_steps': 4, 'lr': 0.0003877184714668627, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:49:30,823] Trial 69 finished with value: -inf and parameters: {'gamma': 0.0011859492189065896, 'max_grad_norm': 4.271951947207975, 'exponent_n_steps': 7, 'lr': 0.0012955883809667053, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:49:39,248] Trial 70 finished with value: -inf and parameters: {'gamma': 0.007172865261966192, 'max_grad_norm': 2.4518755251241395, 'exponent_n_steps': 5, 'lr': 0.0882941178637391, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:49:47,044] Trial 71 finished with value: -inf and parameters: {'gamma': 0.000685103830940351, 'max_grad_norm': 0.7965300040467002, 'exponent_n_steps': 5, 'lr': 0.003368553112057683, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:49:55,320] Trial 72 finished with value: -inf and parameters: {'gamma': 0.00043186805436051226, 'max_grad_norm': 0.4538556218667948, 'exponent_n_steps': 4, 'lr': 0.005294844339871824, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:50:02,825] Trial 73 finished with value: -inf and parameters: {'gamma': 0.0006208170217632201, 'max_grad_norm': 0.504792857887191, 'exponent_n_steps': 5, 'lr': 2.3880997881646914e-05, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:50:12,522] Trial 74 finished with value: -inf and parameters: {'gamma': 0.005547839713617563, 'max_grad_norm': 0.9142759083794371, 'exponent_n_steps': 3, 'lr': 0.0009087326140024541, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:50:21,029] Trial 75 finished with value: -inf and parameters: {'gamma': 0.0008038793464121584, 'max_grad_norm': 3.1182644161613107, 'exponent_n_steps': 4, 'lr': 0.010747002492280062, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:50:28,485] Trial 76 finished with value: -inf and parameters: {'gamma': 0.0002149795045600308, 'max_grad_norm': 1.0391136117611945, 'exponent_n_steps': 5, 'lr': 9.157939730916613e-05, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:50:35,887] Trial 77 finished with value: -inf and parameters: {'gamma': 0.020532948728704786, 'max_grad_norm': 1.7315770625727085, 'exponent_n_steps': 6, 'lr': 0.002756061353305876, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:50:43,639] Trial 78 finished with value: -inf and parameters: {'gamma': 0.01163623015136405, 'max_grad_norm': 0.749993420299352, 'exponent_n_steps': 8, 'lr': 0.041147216896789955, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:50:52,839] Trial 79 finished with value: -inf and parameters: {'gamma': 0.002576153659594284, 'max_grad_norm': 0.6877760044773031, 'exponent_n_steps': 3, 'lr': 0.0017131776685101404, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:51:01,332] Trial 80 finished with value: -inf and parameters: {'gamma': 0.015218049472118526, 'max_grad_norm': 0.42599866707497075, 'exponent_n_steps': 4, 'lr': 4.956459076170661e-05, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:51:09,135] Trial 81 finished with value: -inf and parameters: {'gamma': 0.0012176153729411667, 'max_grad_norm': 0.9222706243787266, 'exponent_n_steps': 7, 'lr': 0.0199259230093591, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:51:16,826] Trial 82 finished with value: -inf and parameters: {'gamma': 0.00030571964853013994, 'max_grad_norm': 0.8412714985072123, 'exponent_n_steps': 6, 'lr': 0.027401861490157515, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:51:24,655] Trial 83 finished with value: -inf and parameters: {'gamma': 0.0022136700996612736, 'max_grad_norm': 1.1945105727668817, 'exponent_n_steps': 7, 'lr': 0.011403658173224616, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:51:33,017] Trial 84 finished with value: -inf and parameters: {'gamma': 0.0037516555703557245, 'max_grad_norm': 0.5887501789557397, 'exponent_n_steps': 5, 'lr': 0.13723498326241887, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:51:41,327] Trial 85 finished with value: -inf and parameters: {'gamma': 0.0005432508299797328, 'max_grad_norm': 3.537720369722024, 'exponent_n_steps': 5, 'lr': 0.056187359466438214, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:51:49,083] Trial 86 finished with value: -inf and parameters: {'gamma': 0.0016018572670660545, 'max_grad_norm': 1.1206561019281644, 'exponent_n_steps': 6, 'lr': 0.39884838530986877, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:51:57,611] Trial 87 finished with value: -inf and parameters: {'gamma': 0.0007901765088039194, 'max_grad_norm': 1.56081157550528, 'exponent_n_steps': 4, 'lr': 0.0006702826997102579, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:52:07,423] Trial 88 finished with value: -inf and parameters: {'gamma': 0.00037438275559946503, 'max_grad_norm': 0.6177333401436559, 'exponent_n_steps': 3, 'lr': 1.763438828396586e-05, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:52:16,196] Trial 89 finished with value: -inf and parameters: {'gamma': 0.0010452837510216805, 'max_grad_norm': 2.2470749536824988, 'exponent_n_steps': 4, 'lr': 0.005836814169671907, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:52:23,483] Trial 90 finished with value: -inf and parameters: {'gamma': 0.000481257471933314, 'max_grad_norm': 1.267381754991301, 'exponent_n_steps': 7, 'lr': 0.1944424913333946, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:52:33,212] Trial 91 finished with value: -inf and parameters: {'gamma': 0.049851847615669354, 'max_grad_norm': 0.5399813566011142, 'exponent_n_steps': 3, 'lr': 0.00024291726147230064, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:52:43,050] Trial 92 finished with value: -inf and parameters: {'gamma': 0.03234232349378097, 'max_grad_norm': 0.6995468386574331, 'exponent_n_steps': 3, 'lr': 3.4629636649439375e-05, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:52:52,797] Trial 93 finished with value: -inf and parameters: {'gamma': 0.06823506006329276, 'max_grad_norm': 0.5849843338859018, 'exponent_n_steps': 3, 'lr': 0.0012801420679340626, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:53:00,820] Trial 94 finished with value: -inf and parameters: {'gamma': 0.09228060547552304, 'max_grad_norm': 0.7769637271524702, 'exponent_n_steps': 4, 'lr': 0.00011228356912909175, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:53:10,629] Trial 95 finished with value: -inf and parameters: {'gamma': 0.024625015156075614, 'max_grad_norm': 0.46225951793578446, 'exponent_n_steps': 3, 'lr': 0.00033176718299238216, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:53:18,912] Trial 96 finished with value: -inf and parameters: {'gamma': 0.008268016511818795, 'max_grad_norm': 2.060563929014136, 'exponent_n_steps': 5, 'lr': 0.00016487784258643147, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:53:25,961] Trial 97 finished with value: -inf and parameters: {'gamma': 0.004757522602714216, 'max_grad_norm': 0.9850322383013653, 'exponent_n_steps': 6, 'lr': 0.0004911743938145328, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:53:34,447] Trial 98 finished with value: -inf and parameters: {'gamma': 0.04488877865704973, 'max_grad_norm': 0.6450972388469052, 'exponent_n_steps': 4, 'lr': 6.296050789920848e-05, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -inf.\n",
            "[I 2025-12-22 03:53:42,051] Trial 99 finished with value: -inf and parameters: {'gamma': 0.00017043132726106815, 'max_grad_norm': 0.8629147815669663, 'exponent_n_steps': 10, 'lr': 1.3537368780616573e-05, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: -inf.\n",
            "[W 2025-12-22 03:53:42,084] Trial 0 is omitted in visualization because its objective value is inf or nan.\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning:\n",
            "\n",
            "datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "\n",
            "[W 2025-12-22 03:53:42,084] Trial 1 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,086] Trial 2 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,087] Trial 3 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,088] Trial 4 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,089] Trial 5 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,091] Trial 6 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,092] Trial 7 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,094] Trial 8 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,095] Trial 9 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,096] Trial 10 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,098] Trial 11 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,100] Trial 12 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,100] Trial 13 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,101] Trial 14 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,102] Trial 15 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,103] Trial 16 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,106] Trial 17 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,107] Trial 18 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,108] Trial 19 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,110] Trial 20 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,111] Trial 21 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,113] Trial 22 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,114] Trial 23 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,115] Trial 24 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,117] Trial 25 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,118] Trial 26 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,119] Trial 27 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,120] Trial 28 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,121] Trial 29 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,122] Trial 30 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,125] Trial 31 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,126] Trial 32 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,127] Trial 33 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,129] Trial 34 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,130] Trial 35 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,131] Trial 36 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,133] Trial 37 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,133] Trial 38 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,135] Trial 39 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,136] Trial 40 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,139] Trial 41 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,140] Trial 42 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,141] Trial 43 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,143] Trial 44 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,144] Trial 45 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,145] Trial 46 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,146] Trial 47 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,148] Trial 48 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,148] Trial 49 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,149] Trial 50 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,151] Trial 51 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,152] Trial 52 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,152] Trial 53 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,153] Trial 54 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,155] Trial 55 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,156] Trial 56 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,156] Trial 57 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,157] Trial 58 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,158] Trial 59 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,159] Trial 60 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,161] Trial 61 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,161] Trial 62 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,162] Trial 63 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,163] Trial 64 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,164] Trial 65 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,165] Trial 66 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,165] Trial 67 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,166] Trial 68 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,167] Trial 69 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,167] Trial 70 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,168] Trial 71 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,168] Trial 72 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,170] Trial 73 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,171] Trial 74 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,171] Trial 75 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,172] Trial 76 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,172] Trial 77 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,172] Trial 78 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,174] Trial 79 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,175] Trial 80 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,175] Trial 81 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,176] Trial 82 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,176] Trial 83 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,177] Trial 84 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,177] Trial 85 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,178] Trial 86 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,178] Trial 87 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,178] Trial 88 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,179] Trial 89 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,179] Trial 90 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,180] Trial 91 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,181] Trial 92 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,181] Trial 93 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,182] Trial 94 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,183] Trial 95 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,183] Trial 96 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,184] Trial 97 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,185] Trial 98 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,185] Trial 99 is omitted in visualization because its objective value is inf or nan.\n",
            "[W 2025-12-22 03:53:42,186] Study instance does not contain completed trials.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of finished trials:  100\n",
            "Best trial:\n",
            "  Value: -inf\n",
            "  Params: \n",
            "    gamma: 0.0005154292404657294\n",
            "    max_grad_norm: 0.5837153849558163\n",
            "    exponent_n_steps: 4\n",
            "    lr: 0.0011194363508517117\n",
            "    net_arch: tiny\n",
            "    activation_fn: relu\n",
            "  User attrs:\n",
            "    gamma_: 0.9994845707595342\n",
            "    n_steps: 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"98df7529-7b77-4c44-9d1b-318fd28f2e7a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"98df7529-7b77-4c44-9d1b-318fd28f2e7a\")) {                    Plotly.newPlot(                        \"98df7529-7b77-4c44-9d1b-318fd28f2e7a\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"y\":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"y\":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#cccccc\"},\"mode\":\"markers\",\"name\":\"Infeasible Trial\",\"showlegend\":false,\"x\":[],\"y\":[],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('98df7529-7b77-4c44-9d1b-318fd28f2e7a');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"6818f485-c06c-4598-bd82-3088d1a0ca99\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6818f485-c06c-4598-bd82-3088d1a0ca99\")) {                    Plotly.newPlot(                        \"6818f485-c06c-4598-bd82-3088d1a0ca99\",                        [],                        {\"title\":{\"text\":\"Hyperparameter Importances\"},\"xaxis\":{\"title\":{\"text\":\"Hyperparameter Importance\"}},\"yaxis\":{\"title\":{\"text\":\"Hyperparameter\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('6818f485-c06c-4598-bd82-3088d1a0ca99');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch as th\n",
        "\n",
        "# Set pytorch num threads to 1 for faster training\n",
        "th.set_num_threads(1)\n",
        "# Select the sampler, can be random, TPESampler, CMAES, ...\n",
        "sampler = TPESampler(n_startup_trials=N_STARTUP_TRIALS)\n",
        "# Do not prune before 1/3 of the max budget is used\n",
        "pruner = MedianPruner(\n",
        "    n_startup_trials=N_STARTUP_TRIALS, n_warmup_steps=N_EVALUATIONS // 3\n",
        ")\n",
        "# Create the study and start the hyperparameter optimization\n",
        "study = optuna.create_study(sampler=sampler, pruner=pruner, direction=\"maximize\")\n",
        "\n",
        "try:\n",
        "    study.optimize(objective, n_trials=N_TRIALS, n_jobs=N_JOBS, timeout=TIMEOUT)\n",
        "except KeyboardInterrupt:\n",
        "    pass\n",
        "\n",
        "print(\"Number of finished trials: \", len(study.trials))\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(f\"  Value: {trial.value}\")\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(f\"    {key}: {value}\")\n",
        "\n",
        "print(\"  User attrs:\")\n",
        "for key, value in trial.user_attrs.items():\n",
        "    print(f\"    {key}: {value}\")\n",
        "\n",
        "# Write report\n",
        "study.trials_dataframe().to_csv(\"study_results_a2c_cartpole.csv\")\n",
        "\n",
        "fig1 = plot_optimization_history(study)\n",
        "fig2 = plot_param_importances(study)\n",
        "\n",
        "fig1.show()\n",
        "fig2.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCbep6z1h3D1"
      },
      "source": [
        "Complete example: https://github.com/DLR-RM/rl-baselines3-zoo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yUeYnfJVpB2"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "What we have seen in this notebook:\n",
        "- the importance of good hyperparameters\n",
        "- how to do automatic hyperparameter search with optuna\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-gqIPXqV7zZ",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "icra22_optuna_lab.ipynb",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}